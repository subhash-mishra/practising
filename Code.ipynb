In [1]: jdnfdnvdn vf b ggb v jfgjfgnfgnf
#library for understanding music
from music21 import *
In [2]:
#defining function to read MIDI files
def read_midi(file):
    
    print("Loading Music File:",file)
    
    notes=[]
    notes_to_parse = None
    
    #parsing a midi file
    midi = converter.parse(file)
  
    #grouping based on different instruments
    s2 = instrument.partitionByInstrument(midi)

    #Looping over all the instruments
    for part in s2.parts:
    
        #select elements of only piano
        if 'Piano' in str(part): 
        
            notes_to_parse = part.recurse() 
      
            #finding whether a particular element is note or a chord
            for element in notes_to_parse:
                
                #note
                if isinstance(element, note.Note):
                    notes.append(str(element.pitch))
                
                #chord
                elif isinstance(element, chord.Chord):
                    notes.append('.'.join(str(n) for n in element.normalOrder))

    return np.array(notes)
In [3]:
#for listing down the file names
import os

#Array Processing
import numpy as np

#specify the path
path='C:/Users/HP/Desktop/Minor/Dataset/'
#read all the filenames
files=[i for i in os.listdir(path) if i.endswith(".mid")]
files
#reading each midi file
notes_array = np.array([read_midi(path+i) for i in files])
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schubert_D850_1.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schubert_D850_2.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schubert_D850_3.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schubert_D850_4.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schubert_D935_1.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schubert_D935_2.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schubert_D935_3.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schubert_D935_4.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schub_d760_1.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schub_d760_2.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schub_d760_3.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schub_d760_4.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schub_d960_1.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schub_d960_2.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schub_d960_3.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schub_d960_4.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schuim-1.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schuim-2.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schuim-3.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schuim-4.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schumm-1.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schumm-2.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schumm-3.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schumm-4.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schumm-5.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schumm-6.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schu_143_1.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schu_143_2.mid
Loading Music File: C:/Users/HP/Desktop/Minor/Dataset/schu_143_3.mid
In [4]:
files
Out[4]:
['schubert_D850_1.mid',
 'schubert_D850_2.mid',
 'schubert_D850_3.mid',
 'schubert_D850_4.mid',
 'schubert_D935_1.mid',
 'schubert_D935_2.mid',
 'schubert_D935_3.mid',
 'schubert_D935_4.mid',
 'schub_d760_1.mid',
 'schub_d760_2.mid',
 'schub_d760_3.mid',
 'schub_d760_4.mid',
 'schub_d960_1.mid',
 'schub_d960_2.mid',
 'schub_d960_3.mid',
 'schub_d960_4.mid',
 'schuim-1.mid',
 'schuim-2.mid',
 'schuim-3.mid',
 'schuim-4.mid',
 'schumm-1.mid',
 'schumm-2.mid',
 'schumm-3.mid',
 'schumm-4.mid',
 'schumm-5.mid',
 'schumm-6.mid',
 'schu_143_1.mid',
 'schu_143_2.mid',
 'schu_143_3.mid']
In [5]:
#converting 2D array into 1D array
notes_ = [element for note_ in notes_array for element in note_]

#No. of unique notes
unique_notes = list(set(notes_))
print(len(unique_notes))
304
In [6]:
#importing library
from collections import Counter

#computing frequency of each note
freq = dict(Counter(notes_))

#library for visualiation
import matplotlib.pyplot as plt

#consider only the frequencies
no=[count for _,count in freq.items()]

#set the figure size
plt.figure(figsize=(5,5))

#plot
plt.hist(no)
Out[6]:
(array([187.,  41.,  26.,  11.,   6.,   9.,  12.,   6.,   3.,   3.]),
 array([1.0000e+00, 1.4790e+02, 2.9480e+02, 4.4170e+02, 5.8860e+02,
        7.3550e+02, 8.8240e+02, 1.0293e+03, 1.1762e+03, 1.3231e+03,
        1.4700e+03]),
 <a list of 10 Patch objects>)

In [7]:
frequent_notes = [note_ for note_, count in freq.items() if count>=50]
print(len(frequent_notes))
167
In [8]:
new_music=[]

for notes in notes_array:
    temp=[]
    for note_ in notes:
        if note_ in frequent_notes:
            temp.append(note_)            
    new_music.append(temp)
    
new_music = np.array(new_music)
In [9]:
no_of_timesteps = 32
x = []
y = []

for note_ in new_music:
    for i in range(0, len(note_) - no_of_timesteps, 1):
        
        #preparing input and output sequences
        input_ = note_[i:i + no_of_timesteps]
        output = note_[i + no_of_timesteps]
        
        x.append(input_)
        y.append(output)
        
x=np.array(x)
y=np.array(y)
In [10]:
unique_x = list(set(x.ravel()))
x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))
In [11]:
#preparing input sequences
x_seq=[]
for i in x:
    temp=[]
    for j in i:
        #assigning unique integer to every note
        temp.append(x_note_to_int[j])
    x_seq.append(temp)
    
x_seq = np.array(x_seq)
In [12]:
unique_y = list(set(y))
y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) 
y_seq=np.array([y_note_to_int[i] for i in y])
In [13]:
from sklearn.model_selection import train_test_split
x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)
In [14]:
def lstm():
  model = Sequential()
  model.add(LSTM(128,return_sequences=True))
  model.add(LSTM(128))
  model.add(Dense(256))
  model.add(Activation('relu'))
  model.add(Dense(n_vocab))
  model.add(Activation('softmax'))
  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')
  return model
In [15]:
from keras.layers import *
from keras.models import *
from keras.callbacks import *
import keras.backend as K

K.clear_session()
model = Sequential()
    
#embedding layer
model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) 

model.add(Conv1D(64,3, padding='causal',activation='relu'))
model.add(Dropout(0.2))
model.add(MaxPool1D(2))
    
model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))
model.add(Dropout(0.2))
model.add(MaxPool1D(2))

model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))
model.add(Dropout(0.2))
model.add(MaxPool1D(2))
          
#model.add(Conv1D(256,5,activation='relu'))    
model.add(GlobalMaxPool1D())
    
model.add(Dense(256, activation='relu'))
model.add(Dense(len(unique_y), activation='softmax'))
    
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')

model.summary()
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, 32, 100)           16700     
_________________________________________________________________
conv1d (Conv1D)              (None, 32, 64)            19264     
_________________________________________________________________
dropout (Dropout)            (None, 32, 64)            0         
_________________________________________________________________
max_pooling1d (MaxPooling1D) (None, 16, 64)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 16, 128)           24704     
_________________________________________________________________
dropout_1 (Dropout)          (None, 16, 128)           0         
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 8, 128)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 8, 256)            98560     
_________________________________________________________________
dropout_2 (Dropout)          (None, 8, 256)            0         
_________________________________________________________________
max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         
_________________________________________________________________
global_max_pooling1d (Global (None, 256)               0         
_________________________________________________________________
dense (Dense)                (None, 256)               65792     
_________________________________________________________________
dense_1 (Dense)              (None, 167)               42919     
=================================================================
Total params: 267,939
Trainable params: 267,939
Non-trainable params: 0
_________________________________________________________________
In [16]:
mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)
In [17]:
history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])
Epoch 1/50
402/403 [============================>.] - ETA: 0s - loss: 4.3303
Epoch 00001: val_loss improved from inf to 4.02231, saving model to best_model.h5
403/403 [==============================] - 32s 79ms/step - loss: 4.3305 - val_loss: 4.0223
Epoch 2/50
402/403 [============================>.] - ETA: 0s - loss: 3.7877
Epoch 00002: val_loss improved from 4.02231 to 3.81296, saving model to best_model.h5
403/403 [==============================] - 32s 79ms/step - loss: 3.7880 - val_loss: 3.8130
Epoch 3/50
402/403 [============================>.] - ETA: 0s - loss: 3.6106
Epoch 00003: val_loss improved from 3.81296 to 3.67870, saving model to best_model.h5
403/403 [==============================] - 30s 76ms/step - loss: 3.6105 - val_loss: 3.6787
Epoch 4/50
402/403 [============================>.] - ETA: 0s - loss: 3.4693
Epoch 00004: val_loss improved from 3.67870 to 3.56613, saving model to best_model.h5
403/403 [==============================] - 30s 75ms/step - loss: 3.4691 - val_loss: 3.5661
Epoch 5/50
402/403 [============================>.] - ETA: 0s - loss: 3.3656
Epoch 00005: val_loss improved from 3.56613 to 3.50325, saving model to best_model.h5
403/403 [==============================] - 31s 76ms/step - loss: 3.3657 - val_loss: 3.5033
Epoch 6/50
402/403 [============================>.] - ETA: 0s - loss: 3.2843
Epoch 00006: val_loss improved from 3.50325 to 3.43494, saving model to best_model.h5
403/403 [==============================] - 31s 77ms/step - loss: 3.2845 - val_loss: 3.4349
Epoch 7/50
402/403 [============================>.] - ETA: 0s - loss: 3.2122
Epoch 00007: val_loss improved from 3.43494 to 3.33534, saving model to best_model.h5
403/403 [==============================] - 32s 79ms/step - loss: 3.2116 - val_loss: 3.3353
Epoch 8/50
402/403 [============================>.] - ETA: 0s - loss: 3.1425
Epoch 00008: val_loss improved from 3.33534 to 3.30109, saving model to best_model.h5
403/403 [==============================] - 31s 76ms/step - loss: 3.1430 - val_loss: 3.3011
Epoch 9/50
402/403 [============================>.] - ETA: 0s - loss: 3.0838
Epoch 00009: val_loss improved from 3.30109 to 3.24716, saving model to best_model.h5
403/403 [==============================] - 32s 79ms/step - loss: 3.0839 - val_loss: 3.2472
Epoch 10/50
402/403 [============================>.] - ETA: 0s - loss: 3.0378
Epoch 00010: val_loss did not improve from 3.24716
403/403 [==============================] - 29s 72ms/step - loss: 3.0377 - val_loss: 3.2530
Epoch 11/50
402/403 [============================>.] - ETA: 0s - loss: 2.9886
Epoch 00011: val_loss improved from 3.24716 to 3.20792, saving model to best_model.h5
403/403 [==============================] - 30s 75ms/step - loss: 2.9883 - val_loss: 3.2079
Epoch 12/50
402/403 [============================>.] - ETA: 0s - loss: 2.9401
Epoch 00012: val_loss improved from 3.20792 to 3.16713, saving model to best_model.h5
403/403 [==============================] - 31s 76ms/step - loss: 2.9403 - val_loss: 3.1671
Epoch 13/50
402/403 [============================>.] - ETA: 0s - loss: 2.9054
Epoch 00013: val_loss improved from 3.16713 to 3.15486, saving model to best_model.h5
403/403 [==============================] - 31s 77ms/step - loss: 2.9057 - val_loss: 3.1549
Epoch 14/50
402/403 [============================>.] - ETA: 0s - loss: 2.8698
Epoch 00014: val_loss improved from 3.15486 to 3.09557, saving model to best_model.h5
403/403 [==============================] - 31s 77ms/step - loss: 2.8696 - val_loss: 3.0956
Epoch 15/50
402/403 [============================>.] - ETA: 0s - loss: 2.8300
Epoch 00015: val_loss did not improve from 3.09557
403/403 [==============================] - 30s 76ms/step - loss: 2.8303 - val_loss: 3.0967
Epoch 16/50
402/403 [============================>.] - ETA: 0s - loss: 2.8067
Epoch 00016: val_loss improved from 3.09557 to 3.06648, saving model to best_model.h5
403/403 [==============================] - 31s 77ms/step - loss: 2.8069 - val_loss: 3.0665
Epoch 17/50
402/403 [============================>.] - ETA: 0s - loss: 2.7662
Epoch 00017: val_loss improved from 3.06648 to 3.03717, saving model to best_model.h5
403/403 [==============================] - 31s 78ms/step - loss: 2.7660 - val_loss: 3.0372
Epoch 18/50
402/403 [============================>.] - ETA: 0s - loss: 2.7415
Epoch 00018: val_loss improved from 3.03717 to 3.01987, saving model to best_model.h5
403/403 [==============================] - 31s 77ms/step - loss: 2.7418 - val_loss: 3.0199
Epoch 19/50
402/403 [============================>.] - ETA: 0s - loss: 2.7121
Epoch 00019: val_loss improved from 3.01987 to 2.99873, saving model to best_model.h5
403/403 [==============================] - 31s 76ms/step - loss: 2.7124 - val_loss: 2.9987
Epoch 20/50
403/403 [==============================] - ETA: 0s - loss: 2.6902
Epoch 00020: val_loss improved from 2.99873 to 2.98881, saving model to best_model.h5
403/403 [==============================] - 31s 76ms/step - loss: 2.6902 - val_loss: 2.9888
Epoch 21/50
402/403 [============================>.] - ETA: 0s - loss: 2.6671
Epoch 00021: val_loss improved from 2.98881 to 2.97604, saving model to best_model.h5
403/403 [==============================] - 30s 75ms/step - loss: 2.6672 - val_loss: 2.9760
Epoch 22/50
402/403 [============================>.] - ETA: 0s - loss: 2.6402
Epoch 00022: val_loss did not improve from 2.97604
403/403 [==============================] - 30s 74ms/step - loss: 2.6398 - val_loss: 2.9869
Epoch 23/50
402/403 [============================>.] - ETA: 0s - loss: 2.6258
Epoch 00023: val_loss improved from 2.97604 to 2.97267, saving model to best_model.h5
403/403 [==============================] - 31s 76ms/step - loss: 2.6259 - val_loss: 2.9727
Epoch 24/50
402/403 [============================>.] - ETA: 0s - loss: 2.6020
Epoch 00024: val_loss improved from 2.97267 to 2.93529, saving model to best_model.h5
403/403 [==============================] - 30s 75ms/step - loss: 2.6021 - val_loss: 2.9353
Epoch 25/50
402/403 [============================>.] - ETA: 0s - loss: 2.5820
Epoch 00025: val_loss improved from 2.93529 to 2.92603, saving model to best_model.h5
403/403 [==============================] - 33s 81ms/step - loss: 2.5821 - val_loss: 2.9260
Epoch 26/50
402/403 [============================>.] - ETA: 0s - loss: 2.5676
Epoch 00026: val_loss improved from 2.92603 to 2.91556, saving model to best_model.h5
403/403 [==============================] - 31s 77ms/step - loss: 2.5673 - val_loss: 2.9156
Epoch 27/50
402/403 [============================>.] - ETA: 0s - loss: 2.5521
Epoch 00027: val_loss did not improve from 2.91556
403/403 [==============================] - 31s 76ms/step - loss: 2.5525 - val_loss: 2.9183
Epoch 28/50
402/403 [============================>.] - ETA: 0s - loss: 2.5381
Epoch 00028: val_loss improved from 2.91556 to 2.89408, saving model to best_model.h5
403/403 [==============================] - 31s 77ms/step - loss: 2.5382 - val_loss: 2.8941
Epoch 29/50
402/403 [============================>.] - ETA: 0s - loss: 2.5268
Epoch 00029: val_loss improved from 2.89408 to 2.88797, saving model to best_model.h5
403/403 [==============================] - 32s 79ms/step - loss: 2.5270 - val_loss: 2.8880
Epoch 30/50
402/403 [============================>.] - ETA: 0s - loss: 2.5017
Epoch 00030: val_loss improved from 2.88797 to 2.87584, saving model to best_model.h5
403/403 [==============================] - 30s 75ms/step - loss: 2.5022 - val_loss: 2.8758
Epoch 31/50
402/403 [============================>.] - ETA: 0s - loss: 2.4983
Epoch 00031: val_loss improved from 2.87584 to 2.86466, saving model to best_model.h5
403/403 [==============================] - 31s 76ms/step - loss: 2.4979 - val_loss: 2.8647
Epoch 32/50
402/403 [============================>.] - ETA: 0s - loss: 2.4780
Epoch 00032: val_loss did not improve from 2.86466
403/403 [==============================] - 30s 75ms/step - loss: 2.4779 - val_loss: 2.8707
Epoch 33/50
402/403 [============================>.] - ETA: 0s - loss: 2.4687
Epoch 00033: val_loss did not improve from 2.86466
403/403 [==============================] - 31s 77ms/step - loss: 2.4686 - val_loss: 2.8716
Epoch 34/50
402/403 [============================>.] - ETA: 0s - loss: 2.4606
Epoch 00034: val_loss improved from 2.86466 to 2.84436, saving model to best_model.h5
403/403 [==============================] - 31s 78ms/step - loss: 2.4610 - val_loss: 2.8444
Epoch 35/50
402/403 [============================>.] - ETA: 0s - loss: 2.4479
Epoch 00035: val_loss did not improve from 2.84436
403/403 [==============================] - 29s 72ms/step - loss: 2.4480 - val_loss: 2.8467
Epoch 36/50
402/403 [============================>.] - ETA: 0s - loss: 2.4461
Epoch 00036: val_loss improved from 2.84436 to 2.83682, saving model to best_model.h5
403/403 [==============================] - 31s 77ms/step - loss: 2.4464 - val_loss: 2.8368
Epoch 37/50
402/403 [============================>.] - ETA: 0s - loss: 2.4200
Epoch 00037: val_loss improved from 2.83682 to 2.81991, saving model to best_model.h5
403/403 [==============================] - 29s 73ms/step - loss: 2.4198 - val_loss: 2.8199
Epoch 38/50
402/403 [============================>.] - ETA: 0s - loss: 2.4217
Epoch 00038: val_loss did not improve from 2.81991
403/403 [==============================] - 29s 73ms/step - loss: 2.4218 - val_loss: 2.8201
Epoch 39/50
402/403 [============================>.] - ETA: 0s - loss: 2.4114
Epoch 00039: val_loss improved from 2.81991 to 2.81040, saving model to best_model.h5
403/403 [==============================] - 29s 73ms/step - loss: 2.4118 - val_loss: 2.8104
Epoch 40/50
402/403 [============================>.] - ETA: 0s - loss: 2.3972
Epoch 00040: val_loss did not improve from 2.81040
403/403 [==============================] - 29s 72ms/step - loss: 2.3969 - val_loss: 2.8270
Epoch 41/50
402/403 [============================>.] - ETA: 0s - loss: 2.3898
Epoch 00041: val_loss did not improve from 2.81040
403/403 [==============================] - 29s 71ms/step - loss: 2.3901 - val_loss: 2.8113
Epoch 42/50
402/403 [============================>.] - ETA: 0s - loss: 2.3822
Epoch 00042: val_loss improved from 2.81040 to 2.80119, saving model to best_model.h5
403/403 [==============================] - 29s 73ms/step - loss: 2.3823 - val_loss: 2.8012
Epoch 43/50
402/403 [============================>.] - ETA: 0s - loss: 2.3732
Epoch 00043: val_loss improved from 2.80119 to 2.80046, saving model to best_model.h5
403/403 [==============================] - 28s 70ms/step - loss: 2.3733 - val_loss: 2.8005
Epoch 44/50
402/403 [============================>.] - ETA: 0s - loss: 2.3678
Epoch 00044: val_loss improved from 2.80046 to 2.78784, saving model to best_model.h5
403/403 [==============================] - 28s 69ms/step - loss: 2.3683 - val_loss: 2.7878
Epoch 45/50
402/403 [============================>.] - ETA: 0s - loss: 2.3595
Epoch 00045: val_loss improved from 2.78784 to 2.78129, saving model to best_model.h5
403/403 [==============================] - 27s 68ms/step - loss: 2.3596 - val_loss: 2.7813
Epoch 46/50
402/403 [============================>.] - ETA: 0s - loss: 2.3529
Epoch 00046: val_loss did not improve from 2.78129
403/403 [==============================] - 27s 68ms/step - loss: 2.3531 - val_loss: 2.7957
Epoch 47/50
402/403 [============================>.] - ETA: 0s - loss: 2.3467
Epoch 00047: val_loss improved from 2.78129 to 2.77797, saving model to best_model.h5
403/403 [==============================] - 28s 70ms/step - loss: 2.3468 - val_loss: 2.7780
Epoch 48/50
402/403 [============================>.] - ETA: 0s - loss: 2.3412
Epoch 00048: val_loss improved from 2.77797 to 2.77733, saving model to best_model.h5
403/403 [==============================] - 31s 78ms/step - loss: 2.3414 - val_loss: 2.7773
Epoch 49/50
402/403 [============================>.] - ETA: 0s - loss: 2.3274
Epoch 00049: val_loss did not improve from 2.77733
403/403 [==============================] - 35s 87ms/step - loss: 2.3275 - val_loss: 2.7804
Epoch 50/50
402/403 [============================>.] - ETA: 0s - loss: 2.3304
Epoch 00050: val_loss improved from 2.77733 to 2.77332, saving model to best_model.h5
403/403 [==============================] - 39s 96ms/step - loss: 2.3303 - val_loss: 2.7733
In [19]:
#loading best model
from keras.models import load_model
model = load_model('best_model.h5')
In [21]:
import random
ind = np.random.randint(0,len(x_val)-1)

random_music = x_val[ind]

predictions=[]
for i in range(10):

    random_music = random_music.reshape(1,no_of_timesteps)

    prob  = model.predict(random_music)[0]
    y_pred= np.argmax(prob,axis=0)
    predictions.append(y_pred)

    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)
    random_music = random_music[1:]
    
print(predictions)
[5, 5, 113, 5, 5, 5, 5, 5, 5, 5]
In [22]:
x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) 
predicted_notes = [x_int_to_note[i] for i in predictions]
In [30]:
def convert_to_midi(prediction_output):
   
    offset = 0
    output_notes = []

    # create note and chord objects based on the values generated by the model
    for pattern in prediction_output:
        
        # pattern is a chord
        if ('.' in pattern) or pattern.isdigit():
            notes_in_chord = pattern.split('.')
            notes = []
            for current_note in notes_in_chord:
                
                cn=int(current_note)
                new_note = note.Note(cn)
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)
                
            new_chord = chord.Chord(notes)
            new_chord.offset = offset
            output_notes.append(new_chord)
            
        # pattern is a note
        else:
            
            new_note = note.Note(pattern)
            new_note.offset = offset
            new_note.storedInstrument = instrument.Piano()
            output_notes.append(new_note)

        # increase offset each iteration so that notes do not stack
        offset += 1
    midi_stream = stream.Stream(output_notes)
    midi_stream.write('midi', fp='music.mid')
In [31]:
convert_to_midi(predicted_notes)
In [29]:
predicted_notes
Out[29]:
['C3', 'C3', 'B-3', 'C3', 'C3', 'C3', 'C3', 'C3', 'C3', 'C3']
In [ ]:
